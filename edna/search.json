[
  {
    "objectID": "workflow.html",
    "href": "workflow.html",
    "title": "Workflow",
    "section": "",
    "text": "Goal: Capture a snapshot of the aquatic community by collecting DNA shed by organisms into the water.\n\n\nCollect surface water using bottles or a bucket.\n\nUse sterile sampling bottles and gloves to avoid contamination.\n\nOptional: record environmental variables (e.g. salinity, temperature, DO)."
  },
  {
    "objectID": "workflow.html#water-collection",
    "href": "workflow.html#water-collection",
    "title": "Workflow",
    "section": "",
    "text": "Goal: Capture a snapshot of the aquatic community by collecting DNA shed by organisms into the water.\n\n\nCollect surface water using bottles or a bucket.\n\nUse sterile sampling bottles and gloves to avoid contamination.\n\nOptional: record environmental variables (e.g. salinity, temperature, DO)."
  },
  {
    "objectID": "workflow.html#filtration",
    "href": "workflow.html#filtration",
    "title": "Workflow",
    "section": "🧪 Filtration",
    "text": "🧪 Filtration\n\nGoal: Concentrate the trace DNA onto a membrane.\n\n\nFilter the water through a filter (e.g. Waterra™) using a peristaltic pump or syringe.\n\nThese filters trap DNA and cell fragments on the internal membrane.\n\nStore filters at -20 °C or lower to preserve DNA integrity."
  },
  {
    "objectID": "workflow.html#dna-extraction",
    "href": "workflow.html#dna-extraction",
    "title": "Workflow",
    "section": "🧬 DNA extraction",
    "text": "🧬 DNA extraction\n\nGoal: Release and purify the DNA from the filters and remove unwanted material.\n\n\nResuspension of the eDNA\n\nRemove the Waterra filters from the freezer in advance and allow them to defrost in the fridge for approximately one hour before extraction.\nClean work area with 25% bleach solution and blue roll.\nFill two 50 mL Falcon tubes (per Waterra) with TE resuspension buffer, making sure to label the tubes with the sample number.\nShake out any residual water from the inlet of the filter. Apply parafilm to cover the smooth outlet of the filter.\nPipette 50 mL of the TE resuspension buffer into the capsule through the ridged inlet and seal with more parafilm.\nAgitate capsule for five minutes.\n\nA fingertip can be placed over each end and the capsule manually shaken, or if parafilm is securely taped into place, the capsule can be held against a vortex.\n\nPour the solution back into the first 50 mL Falcon tube, and repeat steps 5 and 6 for the second 50 mL Falcon tube, ending up with two 50 mL Falcon tubes of eDNA resuspended from the filter in turbid TE buffer.\n\nThe spent Waterra filter can be thrown away.\n\n\n\n\n\n\n\n\nWhat is TE Buffer?\n\n\n\nTE buffer (Tris-EDTA, pH 8.0) is used to gently release DNA from inside the Waterra capsule.\n\nTris or Tris(hydroxymethyl) aminomethane: stabilises pH\n\nMaintaining a stable, slightly alkaline pH is crucial to prevent DNA degradation caused by hydrolysis, which breaks the bonds between nucleotides — the building blocks of DNA.\n\n\n\n\nStructure of DNA (Source: NIH)\n\n\n\nIf pH drops (becomes acidic), DNA is more prone to hydrolytic cleavage — this breaks the bonds between nucleotides and can irreversibly damage the DNA, interfering with downstream steps like PCR and sequencing.\n\nEDTA (Ethylenediaminetetraacetic acid): binds divalent cations (e.g. Mg²⁺, Ca²⁺) to inhibit DNases and protect DNA integrity\n\n\n\n\n\n\n\n\n\nTE Buffer (Tris-EDTA) Recipe – 5 L Total\n\n\n\n\n\n🧾 Ingredients (for 5 L)\n\n250 mL of 1 M Tris-HCl\n→ Final concentration: 50 mM (millimolar)\n100 mL of 0.5 M EDTA\n→ Final concentration: 10 mM (millimolar)\n4,650 mL of ultrapure water\n→ To bring total volume to 5,000 mL (5 L)\n\n\n\n\n🧂 Instructions\n\nIn a clean 5 L glass bottle, add:\n\n250 mL of 1 M Tris-HCl\n100 mL of 0.5 M EDTA\n\nAdd ultrapure water up to the 5 L mark.\nMix thoroughly by gently inverting or stirring.\nLabel with:\n\nContents (e.g. “TE Buffer, pH 8.0”)\nPreparation date\nInitials\n\nStore at room temperature.\n\n\n\n\n\n\nCentrifuging\n\nCentrifuge the two 50 mL Falcon tubes for 10 minutes at 4500 rpm (revolutions per minute, a unit that measures the rotational speed of a centrifuge rotor) to separate debris/sediment from the liquid DNA-containing fraction.\n\nSupernatant: the clear upper layer, containing eDNA in solution\nPellet: the sediment settled at the bottom of the tube\n\n\n\n\nFiltering through funnel filter\n\nAn analytical test filter funnel attached to a Buchner funnel and peristaltic pump is used to filter the buffer mix through a 0.45-micron disc filter (Nalgene™).\nCombine the two Falcon tubes per sample by pouring the now clear supernatant from both tubes through the funnel, trying to retain the sediment in the tubes.\nAdjust the speed of the peristaltic pump to pull the supernatant through the funnel, with an additional minute of filtering to dry the funnel filter disc.\n\nSamples which required multiple filters due to build-up of sediment can be consolidated into one analytical filter funnel.\n\nUpon completion, one funnel filter disc should contain the filtered supernatant, and the remaining sediment should be retained in the original two Falcon tubes.\n\n\n\nQiagen DNeasy PowerWater\n\nFILTER: Remove the upper portion of the disposable filter funnel to expose the white membrane of the filter disc. Using sterile forceps (use 25% bleach solution and rinse with RO water). Roll up the filter membrane with the top side facing inwards, and insert into a 5 mL PowerWater DNA bead tube. Add 1 mL of PW1 solution.\nSEDIMENT: Add 1 mL PW1 solution to one of the Falcon tubes containing sediment. Use the PW1 solution to rinse out the tube into the second Falcon. This sediment in PW1 mixture is then poured into a 5 mL PowerWater DNA bead tube.\n\n\n\n\n\n\n\nBuffer & kit Components\n\n\n\n\nPW1 (lysis buffer): Breaks open cell walls and membranes\n\nLysis: the breakdown of a cell caused by damage to its plasma (outer) membrane\n\nProteinase K: Degrades proteins and DNases that might otherwise destroy DNA\n\nLipids and proteins can act as PCR inhibitors\n\nBeads (inside the bead tube): Provide mechanical disruption during vortexing, especially for tough cell walls (e.g. bacteria, algae)\nQIAshredder column (later step): Removes cellular debris, allowing only the clean lysate to pass through\n\nLysate is the fluid that results from breaking open cells — a mixture that contains all the internal contents of the cells just lysed (broken apart).\nIn DNA extraction:\n\nStart by disrupting the cells (e.g. with Proteinase K and lysis buffers).\nThis releases the DNA into the solution — now called a lysate.\nThe goal is to clean up this lysate to isolate just the DNA, removing all the other cellular “junk”.\n\n\n\n\n\n\n\n\n\n\n\nAdditional notes\n\n\n\n\nAll extractions were carried out in a lateral flow cabinet, regularly sterilised with 25% bleach (dH₂O) to minimise contamination.\nBottles were autoclaved, and all other equipment was sterilised with 50% bleach prior to use.\nAn additional chemical lysis step was incorporated by adding 100 µL Proteinase K and 900 µL PW1 to Eppendorf tubes containing dry filter paper.\nSamples were incubated in a heat block at 56 °C overnight with agitation to promote thorough cell lysis.\nDuring lysis, Waterra disc filters absorbed a large volume of lysate. To recover DNA:\n\nThe soaked filter fragments were transferred into a QIAshredder column\nThe remaining lysate was pooled before proceeding with the DNeasy protocol\n\nA negative control was included in every extraction batch.\nAll extractions and controls were quantified using a Qubit v2 fluorometer with the dsDNA BR Assay Kit (Invitrogen).\n\n\n\n\n\n\n\n\n\nMaterials\n\n\n\nThe following materials are required for the resuspension, filtration, and DNA extraction steps:\n\nTE buffer (50 mM Tris, 10 mM EDTA)\n\n50 mL Falcon tubes\n\nParafilm (for sealing filter ends)\n\nBuchner funnel (connected to peristaltic pump)\n\n0.45-micron disc filter (e.g. Nalgene™)\n\nProteinase K (for protein digestion)\n\nQIAshredder (for lysate clean-up)\n\nDNeasy PowerWater Kit (Qiagen)\n\nBlue roll and bleach (for surface decontamination)"
  },
  {
    "objectID": "workflow.html#dna-quantification-qubit",
    "href": "workflow.html#dna-quantification-qubit",
    "title": "Workflow",
    "section": "🔬 DNA quantification (Qubit)",
    "text": "🔬 DNA quantification (Qubit)\n\nGoal: Measures how much double-stranded DNA (dsDNA) there is in the extract.\n\n\nPrepare Qubit working solution:\n\nMix dye and buffer at a 1:200 ratio (e.g. 199 µL buffer + 1 µL dye per sample).\n\nLabel assay tubes for each standard and sample.\nAdd 190 µL of working solution to each tube.\nAdd 10 µL of your DNA sample (or Qubit standard) into each tube.\nVortex gently and incubate at room temperature for 2 minutes (light-sensitive!).\nInsert tubes one at a time into the Qubit and record concentrations (ng/µL).\n\n\n\n\n\n\n\nExpected results\n\n\n\n\n1–10 ng/µL: Ideal concentration range for downstream PCR\n\n&lt;1 ng/µL: May require re-extraction or increased PCR cycles\n\nControls:\n\nPositive control → should show DNA present\n\nNegative control → should read 0 ng/µL or “Not detected”\n\n\n\n\n\n\n\n\n\n\nBuffer & kit Components\n\n\n\nTo convert:\n\nµL → mL: divide by 1,000 (e.g. 200 µL ÷ 1,000 = 0.2 mL)\nmL → µL: multiply by 1,000 (e.g. 1.5 mL × 1,000 = 1,500 µL)"
  },
  {
    "objectID": "workflow.html#pcr-amplification",
    "href": "workflow.html#pcr-amplification",
    "title": "Workflow",
    "section": "📈 PCR amplification",
    "text": "📈 PCR amplification\n\nGoal: To amplify a target DNA barcode region from eDNA extracts to detectable levels using polymerase chain reaction (PCR).\n\n\nPCR targets a short, standardised gene region (a “barcode”) used for species identification.\nFor fish, the 12S rRNA mitochondrial gene is commonly used as a barcode.\nPrimers are short, synthetic DNA sequences (~18–25 base pairs) that define the start and end points of the target region to be amplified.\nThey are custom-designed and ordered from commercial suppliers (e.g. IDT, Eurofins) and are essential for selectively amplifying barcode regions.\nTwo primers are needed:\n\nA forward primer, which binds to one strand at the start of the barcode region (5′→3′ direction).\nA reverse primer, which binds to the opposite strand at the end of the region (also written 5′→3′ but binds in the reverse orientation).\n\nThese primers flank the barcode, allowing DNA polymerase to copy the specific region between them.\nExample Primers (MiFish 12S):\n\nForward primer: GTCGGTAAAACTCGTGCCAGC (MiFish-U-F)\nReverse primer: CATAGTGGGGTATCTAATCCCAGTTTG (MiFish-U-R)\n\nPCR involves repeated thermal cycling:\n\nDenaturation (~94–95 °C): DNA strands are separated into single strands.\nAnnealing (~50–60 °C): Forward and reverse primers bind to their complementary sequences flanking the target barcode.\nSynthesis/Extension (72 °C): DNA polymerase (e.g. Taq) synthesises new DNA strands between the primers.\n\nThis cycle is repeated ~35–40 times. Each cycle doubles the amount of target DNA.\n\nThe result is millions of identical copies (amplicons) of just the barcode region — ready for sequencing.\n\n\n\n\nPCR process\n\n\n\n\nTypical PCR mix includes:\n\neDNA extract\nForward & reverse primers\nDNA polymerase (e.g. Taq)\ndNTPs (A, T, C, G)\nBuffer\n\nControls:\n\nPositive control: Contains known DNA to confirm amplification\nNegative control: No DNA added — detects contamination\nOptimised annealing temperature: Ensures specific primer binding\n\nAfter PCR, amplicons can be verified using gel electrophoresis before sequencing.\n\n\n\n\n\n\n\nWhat is Taq Polymerase and what does it do?\n\n\n\nTaq polymerase is a DNA polymerase originally isolated from the heat-tolerant bacterium Thermus aquaticus.\n\nIt is heat-stable, meaning it remains active during high-temperature cycles (e.g., 94–95 °C).\nIt is the most widely used enzyme for standard PCR because it:\n\nTolerates repeated heating and cooling\n\nEfficiently synthesises DNA at ~72 °C during the extension step\n\n\nTaq polymerase builds a new strand of DNA by adding nucleotide building blocks (A, T, C, G) to a template strand.\nIt starts at the primer and matches each base with its complement:\n\nA pairs with T\n\nC pairs with G\n\nThis creates a new, complementary strand — essentially copying the original DNA."
  },
  {
    "objectID": "workflow.html#gel-electrophoresis",
    "href": "workflow.html#gel-electrophoresis",
    "title": "Workflow",
    "section": "🧫 Gel electrophoresis",
    "text": "🧫 Gel electrophoresis\n\nGoal: To visually confirm successful PCR amplification and screen for contamination.\n\n\nPCR products are loaded into an agarose gel, a porous matrix made from a seaweed-derived polysaccharide.\n\n\n\n\n\nDNA electrophoresis equipment\n\n\n\n\nWhen an electric current is applied:\n\nNegatively charged DNA migrates toward the positive electrode\nSmaller fragments move faster through the gel pores\n\nLarger fragments move more slowly\n\nAfter running the gel, DNA is stained with a fluorescent dye (e.g., GelRed or SYBR Safe) and visualised under UV or blue light.\nCompare each sample’s band to a DNA ladder (size marker):\n\n*Clear band at expected size** (e.g., 200–600 bp for 12S): PCR likely succeeded\n\nbp (base pairs): the unit used to measure the length of a DNA fragment.\n1 bp = 1 base pair (A–T or C–G)\n200–600 bp means the DNA fragment is 200 to 600 base pairs long\n\nSmearing or multiple bands: Non-specific amplification or degraded DNA\n*No band**: PCR failed or DNA template was insufficient\n\nControl lanes should show:\n\nPositive control → Band present at expected size\n\nNegative control → No bands (confirms absence of contamination)\n\nSamples → Bands at consistent sizes depending on target gene\n\n\nSetup example\n\n\n\nLane\nContents\n\n\n\n\n1\nHyperladder (size marker)\n\n\n2\nPositive control DNA\n\n\n3\nSample 1\n\n\n4\nSample 2\n\n\n…\n…\n\n\nN\nNegative extraction control\n\n\n\n\n\n\n\nIllustration showing DNA bands separated on a gel\n\n\n\n\n\n\n\n\n\nMaterials\n\n\n\n\nAgarose gel\nTAE or TBE buffer\n\nMaintain pH (~8.0)\n\nConduct electric current\n\nContain EDTA to inhibit DNases\n\nDNA stain (GelRed or SYBR Safe)\nHyperladder (DNA size marker)\nGel casting tray & comb\nElectrophoresis chamber and power supply\nUV or blue light transilluminator"
  },
  {
    "objectID": "workflow.html#sequencing",
    "href": "workflow.html#sequencing",
    "title": "Workflow",
    "section": "📦 Sequencing",
    "text": "📦 Sequencing\n\nGoal: To determine which species are present in the sample by reading the DNA sequences of the amplified barcode regions (produced during PCR).\n\nSteps:\n\nPooling\n\nPCR products (amplicons) from different samples are combined into a single sequencing library — a collective pool of DNA fragments prepared for sequencing.\n\nBarcoding (Indexing)\n\nEach sample is tagged with a unique short DNA sequence (barcode/index).\n→ This allows identification of which sequence came from which sample after sequencing.\n→ The process is known as multiplexing.\n\nSequencing\n\nThe final library is loaded into a high-throughput sequencing platform, typically an Illumina MiSeq.\nIllumina uses a method called sequencing by synthesis:\n\nDNA fragments are copied one base at a time\nAs each base is added, it emits a fluorescent signal:\n\nA = green\n\nT = red\n\nC = blue\n\nG = yellow\n\nA camera records these signals base-by-base as a sequence of coloured flashes\n\nEach sequencing run produces FASTQ files containing:\n\nMillions of short DNA reads (typically 150–300 base pairs)\nQuality scores for each base\nEach read ideally corresponds to a copy of the amplified barcode region (e.g. mitochondrial 12S rRNA for fish).\n\nExample: A read like AGCCTTGAGAACTGCTTAC... might be identified as European seabass through comparison with a reference database."
  },
  {
    "objectID": "workflow.html#bioinformatics",
    "href": "workflow.html#bioinformatics",
    "title": "Workflow",
    "section": "💻 Bioinformatics",
    "text": "💻 Bioinformatics\n\nGoal: To process and interpret raw DNA sequence data to identify which species were present in each sample.\n\n\nAfter sequencing (e.g. on an Illumina MiSeq), each sample produces FASTQ files — text files containing:\n\nMillions of short DNA reads\nA quality score for each base indicating confidence in base calls\n\nQuality filtering:\n\nRemove low-quality reads and unreliable base calls\nTrim off:\n\nResidual primers\n\nAdapter sequences\n\nNoisy bases at the ends\nCommon tools: cutadapt,fastp,Trimmomatic`\n\n\nDenoising & dereplication:\n\nThis is where DADA2 plays a central role.\n\n\n\n\n\n\n\n\nWhat is DADA2?\n\n\n\nDADA2 (Divisive Amplicon Denoising Algorithm 2) is an R package that turns raw reads into exact sequences called Amplicon Sequence Variants (ASVs).\nIt models and corrects sequencing errors to recover the true biological sequences present in your samples.\n\n\n\n\n\n\n\nStep\nWhat DADA2 Does\n\n\n\n\nLearn error rates\nBuilds a model of sequencing error patterns\n\n\nDenoise\nCorrects errors and resolves true sequences\n\n\nDereplicate\nMerges identical reads into unique sequences + counts\n\n\nMerge reads\nCombines paired-end reads (forward + reverse)\n\n\nRemove chimeras\nEliminates artificial recombination products from PCR\n\n\nAssign taxonomy\nLabels ASVs using a reference database (e.g. MiFish, GenBank)\n\n\n\n\n\n\nTaxonomic assignment:\n\nASVs are matched to known species or genera using a reference database.\nCommon databases:\n\nGenBank – Broad nucleotide database\nMiFish – Fish-specific 12S rRNA barcodes\n\nBOLD – Barcode of Life Data System (especially for COI gene)\n\nMatching tools:\n\nBLAST – Finds the closest match in a database (e.g. ASV AGCCTTGAGAACTGCTTAC... → Dicentrarchus labrax (European seabass), 99.3% identity)\nQIIME2 – End-to-end pipeline with taxonomy plugins (e.g. BLAST, naive Bayes)\n\nMEGAN – Converts BLAST results into taxonomic trees & summaries\n\n\nThis is where anonymous DNA fragments are assigned species names — transforming data into ecological meaning.\n\n\n\n\n\n\n\nTaxonomic assignment using BLAST and BASTA\n\n\n\nBLAST stands for Basic Local Alignment Search Tool.\n\nIt compares your unknown DNA sequence (e.g. an ASV) against a reference database such as GenBank, BOLD, or MiFish to find the most similar known sequences.\nIt reports:\n\n% Identity – How similar your sequence is to the reference\nQuery Coverage – How much of your ASV aligned with the reference\nvalue – The probability the match is random (lower is better)\n\nExample:\n\nASV: AGCCTTGAGAACTGCTTAC… Best match: Dicentrarchus labrax (European seabass)\nResult: 99.3% identity, 98% coverage, E-value = 2e-50\nStrong evidence that this ASV is from European seabass.\n\n\nBASTA stands for BLAST-based Taxonomic Assignment.\n\nBASTA is a tool that builds on BLAST results, providing automated and reproducible taxonomic assignment using the Last Common Ancestor (LCA) approach.\nWhile BLAST gives a list of possible matches, BASTA summarises those hits and assigns the taxonomy based on:\n\nA consensus of the top hits\nUser-defined thresholds for identity and coverage\nLowest common taxonomic rank shared by all top matches (LCA)\nThis helps avoid overly specific or incorrect species assignments.\n\n\nBLAST finds best matching sequences in a database, and BASTA assigns taxonomy using consensus of BLAST hits.\n\n\n\nGenerate an abundance table:\n\nThe final step is building a species-by-sample matrix to visualise biodiversity patterns.\n\n\n\n\n\nSpecies\nSample 1\nSample 2\nSample 3\n\n\n\n\nEuropean seabass\n2134\n98\n712\n\n\nThree-spine stickleback\n435\n0\n220\n\n\nGoby spp.\n12\n33\n8\n\n\n\n\nThis process turns millions of anonymous DNA fragments into actionable insights:\n\nWhat species were present?\nWhich sites had higher biodiversity?\nHow did communities change across space or time?"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Home",
    "section": "",
    "text": "🧭 Summary: A visual, step-by-step overview of the full workflow\n\n⚗️ Workflow: Detailed methods, protocols, and materials for each stage\n🔬 DADA2: Step-by-step guide to processing eDNA sequence data using the DADA2 pipeline\n\n\n\n\n\neDNA concept (Source: Fishbio)"
  },
  {
    "objectID": "index.html#contents",
    "href": "index.html#contents",
    "title": "Home",
    "section": "",
    "text": "🧭 Summary: A visual, step-by-step overview of the full workflow\n\n⚗️ Workflow: Detailed methods, protocols, and materials for each stage\n🔬 DADA2: Step-by-step guide to processing eDNA sequence data using the DADA2 pipeline\n\n\n\n\n\neDNA concept (Source: Fishbio)"
  },
  {
    "objectID": "hu/summary.html",
    "href": "hu/summary.html",
    "title": "Summary",
    "section": "",
    "text": "💧 Vízgyűjtés\n→ Környezeti vízminták gyűjtése steril technikával.\n🧪 Szűrés\n→ A vizet membránszűrőkön keresztül kell vezetni a környezetből származó szuszpendált DNS (eDNS) összegyűjtése érdekében.\n🧬 DNS extrakció\n→ Izolálja a DNS-t a szűrőkből egy kereskedelmi extrakciós készlet (pl. Qiagen DNeasy) segítségével.\n🔬 DNS mennyiségi meghatározása (Qubit)\n→ Mérje meg a DNS-koncentrációt az extrakció sikerességének értékeléséhez és a PCR-hez elegendő anyag biztosításához.\n📈 PCR-amplifikáció\n→ Használjon primereket egy vonalkódgén (pl. mitokondriális 12S rRNS) megcélzásához és felerősítéséhez termikus ciklizálással.\n🧫 Gélelektroforézis\n→ Futtassa a PCR-termékeket agarózgélen a sikeres amplifikáció és a szennyeződésmentesség ellenőrzése céljából.\n📦 Szekvenálás\n→ Egyesítse a PCR-amplikonokat, adjon hozzá mintaspecifikus vonalkódokat (indexeket), és szekvenálja egy olyan platformon, mint az Illumina MiSeq.\n💻 Bioinformatika\n→ Demultiplexálás, minőségszűrés és taxonómia hozzárendelése a szekvenciaadatokhoz bioinformatikai csővezeték (pl. DADA2) segítségével."
  },
  {
    "objectID": "hu/dada.html",
    "href": "hu/dada.html",
    "title": "DADA2 Pipeline",
    "section": "",
    "text": "Kezdjük párosított végű FASTQ fájlokkal (pl. sample1_R1.fastq, sample1_R2.fastq).\nA fájloknak a következőknek kell lenniük:\n\nDemultiplexelt (minta szerint felosztva)\nPrimer-trimmelt\n\nA DADA2 az előremenő (R1) és a fordított (R2) fájlokat a minta neve alapján automatikusan illeszti egymáshoz.\n\n\n\n\n\n\n\nMiért az előre (R1) és a fordított (R2) olvasatok?\n\n\n\nA párosított végű szekvenálás (pl. Illumina MiSeq) a DNS-fragmentum két végét olvassa, és mintánként két FASTQ-fájlt generál:\n\n“R1.fastq” → Előre olvasás\nR2.fastq → Visszaolvasás\nAz előre olvasás a felső szál 5′ végéről származik\n\nA fordított olvasás az alsó szál 5′ végéről származik (fordított komplementer)\n\nA két leolvasás átfedhet, ami lehetővé teszi a teljes DNS-darab jobb rekonstrukcióját.\n\nA DADA2 páros végű leolvasásokat használ:\n\nfüggetlenül kiszűri és modellezi az egyes irányok hibáit.\nElvegyíti a leolvasásokat az átfedésük segítségével:\n\nA szekvenálási hibák kijavítása\n\nA teljes vonalkód (amplikon) rekonstruálása\n\na pontosság és a felbontás javítása\n\n\n\n\n\nFájl\nLeírás\n\n\n\n\nR1.fastq\nElőre olvasott adatok (5′→3′ egy szálból)\n\n\nR2.fastq\nFordított olvasatok (5′→3′ a másik szálból)\n\n\n\n→ Mindkettőre szükség van a teljes hosszúságú, jó minőségű szekvenciák létrehozásához."
  },
  {
    "objectID": "hu/dada.html#setup-input",
    "href": "hu/dada.html#setup-input",
    "title": "DADA2 Pipeline",
    "section": "",
    "text": "Kezdjük párosított végű FASTQ fájlokkal (pl. sample1_R1.fastq, sample1_R2.fastq).\nA fájloknak a következőknek kell lenniük:\n\nDemultiplexelt (minta szerint felosztva)\nPrimer-trimmelt\n\nA DADA2 az előremenő (R1) és a fordított (R2) fájlokat a minta neve alapján automatikusan illeszti egymáshoz.\n\n\n\n\n\n\n\nMiért az előre (R1) és a fordított (R2) olvasatok?\n\n\n\nA párosított végű szekvenálás (pl. Illumina MiSeq) a DNS-fragmentum két végét olvassa, és mintánként két FASTQ-fájlt generál:\n\n“R1.fastq” → Előre olvasás\nR2.fastq → Visszaolvasás\nAz előre olvasás a felső szál 5′ végéről származik\n\nA fordított olvasás az alsó szál 5′ végéről származik (fordított komplementer)\n\nA két leolvasás átfedhet, ami lehetővé teszi a teljes DNS-darab jobb rekonstrukcióját.\n\nA DADA2 páros végű leolvasásokat használ:\n\nfüggetlenül kiszűri és modellezi az egyes irányok hibáit.\nElvegyíti a leolvasásokat az átfedésük segítségével:\n\nA szekvenálási hibák kijavítása\n\nA teljes vonalkód (amplikon) rekonstruálása\n\na pontosság és a felbontás javítása\n\n\n\n\n\nFájl\nLeírás\n\n\n\n\nR1.fastq\nElőre olvasott adatok (5′→3′ egy szálból)\n\n\nR2.fastq\nFordított olvasatok (5′→3′ a másik szálból)\n\n\n\n→ Mindkettőre szükség van a teljes hosszúságú, jó minőségű szekvenciák létrehozásához."
  },
  {
    "objectID": "hu/dada.html#a-minőség-vizsgálata",
    "href": "hu/dada.html#a-minőség-vizsgálata",
    "title": "DADA2 Pipeline",
    "section": "A minőség vizsgálata",
    "text": "A minőség vizsgálata\n\nplotQualityProfile(fwd)\nplotQualityProfile(rev)\n\n\nElőre olvasott adatok: általában jó minőség\nFordított olvasatok: a minőség gyakran csökken a vége felé.\nHasználja ezt a csonkítási hossz meghatározásához (pl. 240 bp előre, 160 bp hátra)."
  },
  {
    "objectID": "hu/dada.html#szűrés-és-trimmelés",
    "href": "hu/dada.html#szűrés-és-trimmelés",
    "title": "DADA2 Pipeline",
    "section": "Szűrés és trimmelés",
    "text": "Szűrés és trimmelés\n\nfilterAndTrim(fwd, filtF,\n              rev, filtR,\n              truncLen = c(240,160),\n              maxN = 0,\n              maxEE = c(2,2),\n              truncQ = 2,\n              rm.phix = TRUE,\n              compress = TRUE,\n              multithread = TRUE)\n\n\nEltávolítja a rossz minőségű és kétértelmű olvasásokat.\nEltávolítja a PhiX szennyeződéseket\nMintánként visszatartott olvasásszámokat ad ki\n\n\n\n\n\n\n\nMi az a PhiX és miért távolítja el?\n\n\n\nA PhiX (vagy PhiX174) egy kis vírusgenom, amelyet gyakran adnak hozzá kontrollként az Illumina szekvenálási futtatások során.\n\nSegít a szekvenáló kalibrálásában és a teljesítmény javításában alacsony diverzitású minták (például amplikon alapú eDNS) esetén.\nEz nem része a tényleges biológiai mintának, ezért ki kell szűrni.\n\nA DADA2-ben ez automatikusan történik:\n\nrm.phix = TRUE"
  },
  {
    "objectID": "hu/dada.html#hibaarányok-tanulása",
    "href": "hu/dada.html#hibaarányok-tanulása",
    "title": "DADA2 Pipeline",
    "section": "Hibaarányok tanulása",
    "text": "Hibaarányok tanulása\n\nerrF &lt;- learnErrors(filtFs, multithread = TRUE)\nerrR &lt;- learnErrors(filtRs, multithread = TRUE)\n\n\nFelépít egy parametrikus hibamodellt a megfigyelt adatokból.\nKülön-külön az előre és a hátrafelé történő olvasásra"
  },
  {
    "objectID": "hu/dada.html#denoise-sample-inference",
    "href": "hu/dada.html#denoise-sample-inference",
    "title": "DADA2 Pipeline",
    "section": "Denoise / Sample inference",
    "text": "Denoise / Sample inference\n\ndadaFs &lt;- dada(filtFs, err = errF, multithread = TRUE)\ndadaRs &lt;- dada(filtRs, err = errR, multithread = TRUE)\n\n\nA ASV-k (Amplikon szekvencia-változatok) következtetése.\nKorrigálja a szekvenálási hibákat a valódi biológiai szekvenciák azonosításához."
  },
  {
    "objectID": "hu/dada.html#páros-olvasatok-egyesítése",
    "href": "hu/dada.html#páros-olvasatok-egyesítése",
    "title": "DADA2 Pipeline",
    "section": "Páros olvasatok egyesítése",
    "text": "Páros olvasatok egyesítése\n\nmergers &lt;- mergePairs(dadaFs, filtFs, dadaRs, filtRs)\n\n\nÖsszevonja az előre és a hátrafelé olvasott adatokat\nÁtfedés (pl. ≥12 bp) és egyezés szükséges az átfedési régióban."
  },
  {
    "objectID": "hu/dada.html#szekvencia-táblázat-készítése",
    "href": "hu/dada.html#szekvencia-táblázat-készítése",
    "title": "DADA2 Pipeline",
    "section": "Szekvencia táblázat készítése",
    "text": "Szekvencia táblázat készítése\n\nseqtab &lt;- makeSequenceTable(mergers)\n\n\nSorok = minták\nOszlopok = ASV-k\nCellák = olvasott adatok száma"
  },
  {
    "objectID": "hu/dada.html#kimérák-eltávolítása",
    "href": "hu/dada.html#kimérák-eltávolítása",
    "title": "DADA2 Pipeline",
    "section": "Kimérák eltávolítása",
    "text": "Kimérák eltávolítása\n\nseqtab.nochim &lt;- removeBimeraDenovo(seqtab, method = \"consensus\", multithread = TRUE)\n\n\nEltávolítja a PCR leletek (kimérák)\nEgy megtisztított ASV táblázatot eredményez.\n\n\n\n\n\n\n\nMik azok a kimérák és miért kell eltávolítani őket?\n\n\n\nA Chimerák a PCR-amplifikáció során létrehozott mesterséges DNS-szekvenciák.\n\nAkkor jönnek létre, amikor az egyik templátból származó, részben meghosszabbított DNS-szál véletlenül kötődik egy másik, de hasonló templáthoz a következő PCR-ciklusban.\nEzáltal egy olyan hibrid szekvencia jön létre, amely nem létezik egyetlen valódi szervezetben sem.\n\nEzek az artefaktumok:\n\nGyakoriak az amplikon-alapú munkafolyamatokban.\nfelhúzhatják a biológiai sokféleség becslését vagy téves fajmeghatározáshoz vezethetnek."
  },
  {
    "objectID": "hu/dada.html#olvasásvesztés-nyomon-követése",
    "href": "hu/dada.html#olvasásvesztés-nyomon-követése",
    "title": "DADA2 Pipeline",
    "section": "Olvasásvesztés nyomon követése",
    "text": "Olvasásvesztés nyomon követése\n\ngetN &lt;- function(x) sum(getUniques(x))\ntrack &lt;- cbind(out, sapply(dadaFs, getN), sapply(dadaRs, getN), sapply(mergers, getN), rowSums(seqtab.nochim))\ncolnames(track) &lt;- c(\"input\", \"filtered\", \"denoisedF\", \"denoisedR\", \"merged\", \"nonchim\")\n\n\nFigyeli, hogy hány olvasás halad át az egyes lépéseken\nSegít észlelni a nagyobb adatvesztést vagy csővezetékproblémákat"
  },
  {
    "objectID": "hu/dada.html#taxonómia-hozzárendelése",
    "href": "hu/dada.html#taxonómia-hozzárendelése",
    "title": "DADA2 Pipeline",
    "section": "Taxonómia hozzárendelése",
    "text": "Taxonómia hozzárendelése\n\ntaxa &lt;- assignTaxonomy(seqtab.nochim, \"silva_nr_v138_train_set.fa.gz\", multithread = TRUE)\ntaxa &lt;- addSpecies(taxa, \"silva_species_assignment_v138.fa.gz\")\n\n\nAz ASV-k osztályozása egy referenciaadatbázissal (pl. SILVA) való összehasonlítással.\nHozzáadja a fajszintű azonosítókat a pontos egyezésekhez"
  },
  {
    "objectID": "hu/dada.html#nem-kötelező-fajszintű-megfeleltetés",
    "href": "hu/dada.html#nem-kötelező-fajszintű-megfeleltetés",
    "title": "DADA2 Pipeline",
    "section": "Nem kötelező: Fajszintű megfeleltetés",
    "text": "Nem kötelező: Fajszintű megfeleltetés\n\nHasználjon kurátori referenciákat, mint például a MiFish a hal-specifikus azonosításhoz.\nAlternatívák:\n\nBLAST a fajok kézi ellenőrzéséhez\nDECIPHER IdTaxa() függvénye."
  },
  {
    "objectID": "hu/dada.html#validálás-mock-közösséggel",
    "href": "hu/dada.html#validálás-mock-közösséggel",
    "title": "DADA2 Pipeline",
    "section": "Validálás mock közösséggel",
    "text": "Validálás mock közösséggel\n\nA csővezeték futtatása egy ismert “mock” mintán\nA várt fajokat nagy pontossággal vissza kell állítania"
  },
  {
    "objectID": "hu/dada.html#exportálás-a-phyloseq-be",
    "href": "hu/dada.html#exportálás-a-phyloseq-be",
    "title": "DADA2 Pipeline",
    "section": "Exportálás a phyloseq-be",
    "text": "Exportálás a phyloseq-be\n\nlibrary(phyloseq)\nps &lt;- phyloseq(otu_table(seqtab.nochim, taxa_are_rows = FALSE),\n               tax_table(taxa),\n               sample_data(metadata))\n\n\nLehetővé teszi a diverzitáselemzést, ordinációt, vizualizálást."
  },
  {
    "objectID": "hu/dada.html#összefoglaló-áramlás",
    "href": "hu/dada.html#összefoglaló-áramlás",
    "title": "DADA2 Pipeline",
    "section": "Összefoglaló áramlás",
    "text": "Összefoglaló áramlás\n\n\n\nLépés\nMűvelet\n\n\n\n\n1\nFASTQ fájlok importálása\n\n\n2\nA minőség vizualizálása\n\n\n3\nOlvasások szűrése és trimmelése\n\n\n4\nHibaarányok megismerése\n\n\n5\nASV-k következtetése (denoise)\n\n\n6\nPáros olvasatok egyesítése\n\n\n7\nSzekvencia táblázat készítése\n\n\n8\nKimérák eltávolítása\n\n\n9\nOlvasásmegmaradás nyomon követése\n\n\n10\nTaxonómia hozzárendelése\n\n\n11\nVálasztható: fajmegfeleltetés\n\n\n12\nValidálás ismert mintákkal\n\n\n13\nExportálás a phyloseq-be"
  },
  {
    "objectID": "hu/dada.html#példa-kód",
    "href": "hu/dada.html#példa-kód",
    "title": "DADA2 Pipeline",
    "section": "Példa kód",
    "text": "Példa kód\n\n# Szükséges könyvtárak betöltése\nlibrary(dada2)\nlibrary(phyloseq)\nlibrary(Biostrings)\nlibrary(ggplot2)\n\n# File set up\npath &lt;- \"MiSeq_SOP\"\nlist.files(path)\n\n# Forward és reverse fastq fájlnevek formátuma: SAMPLENAME_R1_001.fastq és SAMPLENAME_R2_001.fastq\nfnFs &lt;- sort(list.files(path, pattern=\"_R1_001.fastq\", full.names = TRUE))\nfnRs &lt;- sort(list.files(path, pattern=\"_R2_001.fastq\", full.names = TRUE))\n\n# Mintanevek kivonása, feltételezve, hogy a fájlnevek formátumúak: SAMPLENAME_XXX.fastq\nsample.names &lt;- sapply(strsplit(basename(fnFs), \"_\"), `[`, 1)\n\n# Minőségi vizsgálat\nplotQualityProfile(fnFs[1:2])\nplotQualityProfile(fnRs[1:2])\n\n# Filter & trim\nfiltFs &lt;- file.path(path, \"filtered\", basename(fnFs))\nfiltRs &lt;- file.path(path, \"filtered\", basename(fnRs))\nout &lt;- filterAndTrim(fnFs, filtFs, fnRs, filtRs,\n                     truncLen=c(240,200), maxN=0, maxEE=c(2,2),\n                     truncQ=2, rm.phix=TRUE, compress=TRUE, multithread=FALSE)\nhead(out)\n\n# Hibaarányok tanulása\nerrF &lt;- learnErrors(filtFs, multithread=FALSE)\nerrR &lt;- learnErrors(filtRs, multithread=FALSE)\nplotErrors(errF, nominalQ=TRUE)\n\n# Dereplikálás\nderepFs &lt;- derepFastq(filtFs, verbose=TRUE)\nderepRs &lt;- derepFastq(filtRs, verbose=TRUE)\n\n# DADA denoising\ndadaFs &lt;- dada(derepFs, err=errF, multithread=FALSE)\ndadaRs &lt;- dada(derepRs, err=errR, multithread=FALSE)\n\n# Páros olvasások egyesítése\nmergers &lt;- mergePairs(dadaFs, derepFs, dadaRs, derepRs, verbose=TRUE)\n\n# ASV táblázat létrehozása\nseqtab &lt;- makeSequenceTable(mergers)\ndim(seqtab)\ntable(nchar(getSequences(seqtab)))\n\n# Vegyük ki a kimérákat\nseqtab.nochim &lt;- removeBimeraDenovo(seqtab, method=\"consensus\",\n                                    multithread=FALSE, verbose=TRUE)\nsum(seqtab.nochim)/sum(seqtab)\n\n# Kövesse nyomon az olvasásokat a csővezetéken keresztül\ngetN &lt;- function(x) sum(getUniques(x))\ntrack &lt;- data.frame(\n  input=out[,1],\n  filtered=out[,2],\n  denoisedF=sapply(dadaFs, getN),\n  denoisedR=sapply(dadaRs, getN),\n  merged=sapply(mergers, getN),\n  nonchim=rowSums(seqtab.nochim)\n)\nrownames(track) &lt;- sample.names &lt;- sapply(strsplit(basename(fnFs), \"_\"), `[`, 1)\nprint(track)\n\n# Taxonómiai hozzárendelés (Silva v138 képzett osztályozóval)\ntaxa &lt;- assignTaxonomy(seqtab.nochim, \"silva_nr_v138_train_set.fa.gz\", multithread=FALSE)\nprint(head(taxa))\n\n# A szekvencia rowname-ek eltávolítása csak megjelenítés céljából\ntaxa.print &lt;- taxa\nrownames(taxa.print) &lt;- NULL\nhead(taxa.print)\n\n# Pontosság kiértékelése\nrownames(seqtab.nochim)\nsample.names &lt;- sapply(strsplit(rownames(seqtab.nochim), \"_\"), `[`, 1)\nrownames(seqtab.nochim) &lt;- sample.names\n\nunqs.mock &lt;- seqtab.nochim[\"Mock\",]\nunqs.mock &lt;- sort(unqs.mock[unqs.mock&gt;0], decreasing=TRUE) # A Mockban nem szereplő ASV-k elhagyása.\ncat(\"DADA2 inferred\", length(unqs.mock), \"minta szekvenciák jelen vannak a Mock közösségben.\\n\")\n\n# Töltsük be a várható referencia szekvenciákat a Mock közösséghez.\nmock.ref &lt;- getSequences(file.path(path, \"HMP_MOCK.v35.fasta\"))\nmatch.ref &lt;- sum(sapply(names(unqs.mock), function(x) any(grepl(x, mock.ref)))))\ncat(\"Ezek közül\", sum(match.ref), \"pontosan megegyeztek a várt referencia szekvenciákkal.\\n\")\n\n######\n\ntheme_set(theme_bw())\n\nsamples.out &lt;- rownames(seqtab.nochim)\nsubject &lt;- sapply(strsplit(samples.out, \"D\"), `[`, 1)\ngender &lt;- substr(subject,1,1)\nsubject &lt;- substr(subject,2,999)\nday &lt;- as.integer(sapply(strsplit(samples.out, \"D\"), `[`, 2))\nsamdf &lt;- data.frame(Subject=subject, Gender=gender, Day=day)\nsamdf$When &lt;- \"Early\"\nsamdf$When[samdf$Day&gt;100] &lt;- \"Late\"\nrownames(samdf) &lt;- samples.out\n\nps &lt;- phyloseq(otu_table(seqtab.nochim, taxa_are_rows=FALSE),\n               sample_data(samdf),\n               tax_table(taxa))\nps &lt;- prune_samples(sample_names(ps) != \"Mock\", ps) # Mock minta eltávolítása\n\ndna &lt;- Biostrings::DNAStringSet(taxa_names(ps))\nnames(dna) &lt;- taxa_names(ps)\nps &lt;- merge_phyloseq(ps, dna)\ntaxa_names(ps) &lt;- paste0(\"ASV\", seq(ntaxa(ps)))\nps\n\n# Alfa diverzitás\nplot_richness(ps, x=\"Day\", measures=c(\"Shannon\", \"Simpson\"), color=\"When\")\n\n# Béta diverzitás\nps.prop &lt;- transform_sample_counts(ps, function(otu) otu/sum(otu))\nord.nmds.bray &lt;- ordinate(ps.prop, method=\"NMDS\", distance=\"bray\")\n\nplot_ordination(ps.prop, ord.nmds.bray, color=\"When\", title=\"Bray NMDS\")\n\ntop20 &lt;- names(sort(taxa_sums(ps), decreasing=TRUE))[1:20]\nps.top20 &lt;- transform_sample_counts(ps, function(OTU) OTU/sum(OTU))\nps.top20 &lt;- prune_taxa(top20, ps.top20)\nplot_bar(ps.top20, x=\"Day\", fill=\"Family\") + facet_wrap(~When, scales=\"free_x\")"
  },
  {
    "objectID": "hu/dada.html#a-relatív-abundancia-megértése-az-edns-vizsgálatokban",
    "href": "hu/dada.html#a-relatív-abundancia-megértése-az-edns-vizsgálatokban",
    "title": "DADA2 Pipeline",
    "section": "A relatív abundancia megértése az eDNS-vizsgálatokban",
    "text": "A relatív abundancia megértése az eDNS-vizsgálatokban\n\n\n\n\n\n\nRRA\n\n\n\nAz eDNS használatakor a teljes mintának csak egy részét használjuk fel, és a PCR torzítást eredményez azáltal, hogy több millió DNS-kópiát hoz létre. Ez felveti a kérdést:\nHogyan bízhatunk abban, hogy a leolvasott DNS-ek száma (vagy a “leolvasások száma”) tükrözi a fajok valódi gyakoriságát a környezetben?\nA PCR exponenciálisan sokszorozza a DNS-t - ideális esetben minden egyes ciklusban megduplázza a DNS-kópiák számát. Ez a folyamat azonban az amplifikációs torzítást eredményez, mint például:\n\nPrimerhatékonysági torzítás: egyes szekvenciák jobban kötődnek a primerekhez és könnyebben amplifikálódnak.\nSablonpreferencia: bizonyos DNS-szekvenciák előnyben részesülnek a másolás során.\nPlateau-effektus: az erőforrások kimerülésével az amplifikáció lelassul és leáll.\nRészmintavételezés: a teljes DNS-nek csak egy kis részét használják fel a PCR-hez és a szekvenáláshoz.\n\nEz azt jelenti, hogy a PCR nem őrzi meg pontosan a DNS eredeti arányait - a DNS jelenlétét igazolja, de nem a tökéletes bőséget. A leolvasásszámlálás még mindig hasznos, de óvatosan. Míg a PCR torzítja az abszolút mennyiségeket, a leolvasott számok még mindig ökológiai jeleket hordoznak, különösen a domináns fajok esetében. A kutatók jellemzően a következőket használják:\n\nRelatív leolvasásszám (Relative Read Abundance, RRA):\n\nA leolvasások 40%-a = európai tengeri sügér\nA leolvasások 10%-a = háromágú pálcikacsík.\n\n\nAz RRA lehetővé teszi a mintázatok összehasonlítását a különböző helyszíneken vagy körülmények között, nem pedig a pontos organizmusszámok összehasonlítását.\nA szekvenálás után egy olvasatszámtáblázat mutatja, hogy az egyes fajok esetében mintánként hány olvasatot detektáltunk. Ahhoz, hogy ezek az adatok összehasonlíthatóak legyenek, a következő technikákat alkalmazzuk:\nNormalizálás\nCél: A különböző szekvenálási mélységek (azaz a mintánkénti különböző teljes olvasatszámok) kiigazítása.\n\nArányos skálázás: a nyers számokat relatív arányokká (az összes olvasat %-ában) alakítja át.\nLog-transzformáció: tompítja a nagyon gyakori fajok hatását.\nModellalapú megközelítések: pl. DESeq2, edgeR - a számlálási variabilitást statisztikailag figyelembe veszi.\n\nRarefaction\nCél: A szekvenálási ráfordítások standardizálása a minták között.\n\nMinden adatkészletet közös olvasatszámra (pl. 10 000 olvasat mintánként) vegyen részmintát.\nBiztosítja a diverzitás tisztességes összehasonlítását.\nMegakadályozza a gazdagság túlbecslését a mélyebben szekvenált mintákban.\n\nKompromisszum: egyes adatok (pl. ritka olvasatok) elvesznek, de az eredmények kevésbé torzítottak.\nStatisztikai eszközök\nMiután az adatokat normalizáltuk vagy ritkítottuk, különböző ökológiai és statisztikai elemzéseket alkalmazhatunk:\n\nDiverzitási indexek: Shannon, Simpson - a fajgazdagság és az egyenletesség mérésére.\nRendezés: PCA, NMDS, PCoA - a helyszínek közötti mintázatok megjelenítésére.\nHipotézisvizsgálat: PERMANOVA, ANOSIM - csoportok vagy kezelések összehasonlítására\nÖkológiai modellezés: A környezeti tényezők és a közösségek közötti kapcsolatok feltárása"
  },
  {
    "objectID": "dada.html",
    "href": "dada.html",
    "title": "DADA2 Pipeline",
    "section": "",
    "text": "Start with paired-end FASTQ files (e.g. sample1_R1.fastq, sample1_R2.fastq)\nFiles must be:\n\nDemultiplexed (split by sample)\nPrimer-trimmed\n\nDADA2 matches forward (R1) and reverse (R2) files automatically by sample name.\n\n\n\n\n\n\n\nWhy forward (R1) and reverse (R2) reads?\n\n\n\nPaired-end sequencing (e.g. Illumina MiSeq) reads both ends of a DNA fragment, generating two FASTQ files per sample:\n\nR1.fastq → Forward read\nR2.fastq → Reverse read\nThe forward read comes from the 5′ end of the top strand\n\nThe reverse read comes from the 5′ end of the bottom strand (reverse complement)\n\nThe two reads may overlap, allowing better reconstruction of the full DNA fragment\n\nDADA2 uses paired-end reads to:\n\nIndependently filter and model errors in each direction\n\nMerge the reads using their overlap to:\n\nCorrect sequencing errors\n\nReconstruct the full barcode (amplicon)\n\nImprove accuracy and resolution\n\n\n\n\n\nFile\nDescription\n\n\n\n\nR1.fastq\nForward reads (5′→3′ of one strand)\n\n\nR2.fastq\nReverse reads (5′→3′ of the other strand)\n\n\n\n→ Both are needed to build full-length, high-quality sequences."
  },
  {
    "objectID": "dada.html#setup-input",
    "href": "dada.html#setup-input",
    "title": "DADA2 Pipeline",
    "section": "",
    "text": "Start with paired-end FASTQ files (e.g. sample1_R1.fastq, sample1_R2.fastq)\nFiles must be:\n\nDemultiplexed (split by sample)\nPrimer-trimmed\n\nDADA2 matches forward (R1) and reverse (R2) files automatically by sample name.\n\n\n\n\n\n\n\nWhy forward (R1) and reverse (R2) reads?\n\n\n\nPaired-end sequencing (e.g. Illumina MiSeq) reads both ends of a DNA fragment, generating two FASTQ files per sample:\n\nR1.fastq → Forward read\nR2.fastq → Reverse read\nThe forward read comes from the 5′ end of the top strand\n\nThe reverse read comes from the 5′ end of the bottom strand (reverse complement)\n\nThe two reads may overlap, allowing better reconstruction of the full DNA fragment\n\nDADA2 uses paired-end reads to:\n\nIndependently filter and model errors in each direction\n\nMerge the reads using their overlap to:\n\nCorrect sequencing errors\n\nReconstruct the full barcode (amplicon)\n\nImprove accuracy and resolution\n\n\n\n\n\nFile\nDescription\n\n\n\n\nR1.fastq\nForward reads (5′→3′ of one strand)\n\n\nR2.fastq\nReverse reads (5′→3′ of the other strand)\n\n\n\n→ Both are needed to build full-length, high-quality sequences."
  },
  {
    "objectID": "dada.html#inspecting-quality",
    "href": "dada.html#inspecting-quality",
    "title": "DADA2 Pipeline",
    "section": "Inspecting quality",
    "text": "Inspecting quality\n\nplotQualityProfile(fwd)\nplotQualityProfile(rev)\n\n\nForward reads: generally good quality\nReverse reads: quality often drops toward the end\nUse this to decide truncation lengths (e.g. 240 bp forward, 160 bp reverse)"
  },
  {
    "objectID": "dada.html#filter-trim",
    "href": "dada.html#filter-trim",
    "title": "DADA2 Pipeline",
    "section": "Filter & trim",
    "text": "Filter & trim\n\nfilterAndTrim(fwd, filtF,\n              rev, filtR,\n              truncLen = c(240,160),\n              maxN = 0,\n              maxEE = c(2,2),\n              truncQ = 2,\n              rm.phix = TRUE,\n              compress = TRUE,\n              multithread = TRUE)\n\n\nRemoves poor-quality and ambiguous reads\nDrops PhiX contaminants\nOutputs retained read counts per sample\n\n\n\n\n\n\n\nWhat is PhiX and why is it removed?\n\n\n\nPhiX (or PhiX174) is a small viral genome often added as a control during Illumina sequencing runs.\n\nIt helps calibrate the sequencer and improve performance in low-diversity samples (like amplicon-based eDNA).\nIt’s not part of your actual biological sample, so it needs to be filtered out.\n\nIn DADA2, this is done automatically:\n\nrm.phix = TRUE"
  },
  {
    "objectID": "dada.html#learn-error-rates",
    "href": "dada.html#learn-error-rates",
    "title": "DADA2 Pipeline",
    "section": "Learn error rates",
    "text": "Learn error rates\n\nerrF &lt;- learnErrors(filtFs, multithread = TRUE)\nerrR &lt;- learnErrors(filtRs, multithread = TRUE)\n\n\nBuilds a parametric error model from observed data\nSeparately for forward and reverse reads"
  },
  {
    "objectID": "dada.html#denoise-sample-inference",
    "href": "dada.html#denoise-sample-inference",
    "title": "DADA2 Pipeline",
    "section": "Denoise / Sample inference",
    "text": "Denoise / Sample inference\n\ndadaFs &lt;- dada(filtFs, err = errF, multithread = TRUE)\ndadaRs &lt;- dada(filtRs, err = errR, multithread = TRUE)\n\n\nInfers ASVs (Amplicon Sequence Variants)\nCorrects sequencing errors to identify true biological sequences"
  },
  {
    "objectID": "dada.html#merge-paired-reads",
    "href": "dada.html#merge-paired-reads",
    "title": "DADA2 Pipeline",
    "section": "Merge paired reads",
    "text": "Merge paired reads\n\nmergers &lt;- mergePairs(dadaFs, filtFs, dadaRs, filtRs)\n\n\nMerges forward and reverse reads\nRequires overlap (e.g., ≥12 bp) and agreement in the overlap region"
  },
  {
    "objectID": "dada.html#build-sequence-table",
    "href": "dada.html#build-sequence-table",
    "title": "DADA2 Pipeline",
    "section": "Build sequence table",
    "text": "Build sequence table\n\nseqtab &lt;- makeSequenceTable(mergers)\n\n\nRows = samples\nColumns = ASVs\nCells = read counts"
  },
  {
    "objectID": "dada.html#chimera-removal",
    "href": "dada.html#chimera-removal",
    "title": "DADA2 Pipeline",
    "section": "Chimera removal",
    "text": "Chimera removal\n\nseqtab.nochim &lt;- removeBimeraDenovo(seqtab, method = \"consensus\", multithread = TRUE)\n\n\nRemoves PCR artifacts (chimeras)\nYields a cleaned-up ASV table\n\n\n\n\n\n\n\nWhat are chimeras and why remove them?\n\n\n\nChimeras are artificial DNA sequences created during PCR amplification.\n\nThey form when a partially extended DNA strand from one template accidentally binds to a different, but similar, template in the next PCR cycle.\nThis creates a hybrid sequence that does not exist in any real organism.\n\nThese artefacts:\n\nAre common in amplicon-based workflows.\nCan inflate biodiversity estimates or lead to false species detections."
  },
  {
    "objectID": "dada.html#track-read-loss",
    "href": "dada.html#track-read-loss",
    "title": "DADA2 Pipeline",
    "section": "Track read loss",
    "text": "Track read loss\n\ngetN &lt;- function(x) sum(getUniques(x))\ntrack &lt;- cbind(out, sapply(dadaFs, getN), sapply(dadaRs, getN), sapply(mergers, getN), rowSums(seqtab.nochim))\ncolnames(track) &lt;- c(\"input\", \"filtered\", \"denoisedF\", \"denoisedR\", \"merged\", \"nonchim\")\n\n\nMonitors how many reads pass each step\nHelps catch major data loss or pipeline issues"
  },
  {
    "objectID": "dada.html#assign-taxonomy",
    "href": "dada.html#assign-taxonomy",
    "title": "DADA2 Pipeline",
    "section": "Assign taxonomy",
    "text": "Assign taxonomy\n\ntaxa &lt;- assignTaxonomy(seqtab.nochim, \"silva_nr_v138_train_set.fa.gz\", multithread = TRUE)\ntaxa &lt;- addSpecies(taxa, \"silva_species_assignment_v138.fa.gz\")\n\n\nClassifies ASVs by comparing to a reference database (e.g., SILVA)\nAdds species-level IDs for exact matches"
  },
  {
    "objectID": "dada.html#optional-species-level-matching",
    "href": "dada.html#optional-species-level-matching",
    "title": "DADA2 Pipeline",
    "section": "Optional: Species-level matching",
    "text": "Optional: Species-level matching\n\nUse curated references like MiFish for fish-specific identification\nAlternatives:\n\nBLAST for manual species checks\nDECIPHER’s IdTaxa() function"
  },
  {
    "objectID": "dada.html#validate-with-mock-community",
    "href": "dada.html#validate-with-mock-community",
    "title": "DADA2 Pipeline",
    "section": "Validate with mock community",
    "text": "Validate with mock community\n\nRun pipeline on a known “mock” sample\nShould recover expected species with high accuracy"
  },
  {
    "objectID": "dada.html#export-to-phyloseq",
    "href": "dada.html#export-to-phyloseq",
    "title": "DADA2 Pipeline",
    "section": "Export to phyloseq",
    "text": "Export to phyloseq\n\nlibrary(phyloseq)\nps &lt;- phyloseq(otu_table(seqtab.nochim, taxa_are_rows = FALSE),\n               tax_table(taxa),\n               sample_data(metadata))\n\n\nEnables diversity analysis, ordination, visualisation"
  },
  {
    "objectID": "dada.html#summary-flow",
    "href": "dada.html#summary-flow",
    "title": "DADA2 Pipeline",
    "section": "Summary flow",
    "text": "Summary flow\n\n\n\nStep\nAction\n\n\n\n\n1\nImport FASTQ files\n\n\n2\nVisualise quality\n\n\n3\nFilter & trim reads\n\n\n4\nLearn error rates\n\n\n5\nInfer ASVs (denoise)\n\n\n6\nMerge paired reads\n\n\n7\nBuild sequence table\n\n\n8\nRemove chimeras\n\n\n9\nTrack read retention\n\n\n10\nAssign taxonomy\n\n\n11\nOptional: species matching\n\n\n12\nValidate with known samples\n\n\n13\nExport to phyloseq"
  },
  {
    "objectID": "dada.html#example-code",
    "href": "dada.html#example-code",
    "title": "DADA2 Pipeline",
    "section": "Example code",
    "text": "Example code\n\n# Load necessary libraries\nlibrary(dada2)\nlibrary(phyloseq)\nlibrary(Biostrings)\nlibrary(ggplot2)\n\n# File set up\npath &lt;- \"MiSeq_SOP\"\nlist.files(path)\n\n# Forward and reverse fastq filenames have format: SAMPLENAME_R1_001.fastq and SAMPLENAME_R2_001.fastq\nfnFs &lt;- sort(list.files(path, pattern=\"_R1_001.fastq\", full.names = TRUE))\nfnRs &lt;- sort(list.files(path, pattern=\"_R2_001.fastq\", full.names = TRUE))\n\n# Extract sample names, assuming filenames have format: SAMPLENAME_XXX.fastq\nsample.names &lt;- sapply(strsplit(basename(fnFs), \"_\"), `[`, 1)\n\n# Inspect quality\nplotQualityProfile(fnFs[1:2])\nplotQualityProfile(fnRs[1:2])\n\n# Filter & trim\nfiltFs &lt;- file.path(path, \"filtered\", basename(fnFs))\nfiltRs &lt;- file.path(path, \"filtered\", basename(fnRs))\nout &lt;- filterAndTrim(fnFs, filtFs, fnRs, filtRs,\n                     truncLen=c(240,200), maxN=0, maxEE=c(2,2),\n                     truncQ=2, rm.phix=TRUE, compress=TRUE, multithread=FALSE)\nhead(out)\n\n# Learn error rates\nerrF &lt;- learnErrors(filtFs, multithread=FALSE)\nerrR &lt;- learnErrors(filtRs, multithread=FALSE)\nplotErrors(errF, nominalQ=TRUE)\n\n# Dereplicate\nderepFs &lt;- derepFastq(filtFs, verbose=TRUE)\nderepRs &lt;- derepFastq(filtRs, verbose=TRUE)\n\n# DADA denoising\ndadaFs &lt;- dada(derepFs, err=errF, multithread=FALSE)\ndadaRs &lt;- dada(derepRs, err=errR, multithread=FALSE)\n\n# Merge paired reads\nmergers &lt;- mergePairs(dadaFs, derepFs, dadaRs, derepRs, verbose=TRUE)\n\n# Create ASV table\nseqtab &lt;- makeSequenceTable(mergers)\ndim(seqtab)\ntable(nchar(getSequences(seqtab)))\n\n# Remove chimeras\nseqtab.nochim &lt;- removeBimeraDenovo(seqtab, method=\"consensus\",\n                                    multithread=FALSE, verbose=TRUE)\nsum(seqtab.nochim)/sum(seqtab)\n\n# Track reads through pipeline\ngetN &lt;- function(x) sum(getUniques(x))\ntrack &lt;- data.frame(\n  input=out[,1],\n  filtered=out[,2],\n  denoisedF=sapply(dadaFs, getN),\n  denoisedR=sapply(dadaRs, getN),\n  merged=sapply(mergers, getN),\n  nonchim=rowSums(seqtab.nochim)\n)\nrownames(track) &lt;- sample.names &lt;- sapply(strsplit(basename(fnFs), \"_\"), `[`, 1)\nprint(track)\n\n# Taxonomic assignment (using Silva v138 trained classifier)\ntaxa &lt;- assignTaxonomy(seqtab.nochim, \"silva_nr_v138_train_set.fa.gz\", multithread=FALSE)\nprint(head(taxa))\n\n# Removing sequence rownames for display only\ntaxa.print &lt;- taxa\nrownames(taxa.print) &lt;- NULL\nhead(taxa.print)\n\n# Evaluate accuracy\nrownames(seqtab.nochim)\nsample.names &lt;- sapply(strsplit(rownames(seqtab.nochim), \"_\"), `[`, 1)\nrownames(seqtab.nochim) &lt;- sample.names\n\nunqs.mock &lt;- seqtab.nochim[\"Mock\",]\nunqs.mock &lt;- sort(unqs.mock[unqs.mock&gt;0], decreasing=TRUE) # Drop ASVs absent in the Mock\ncat(\"DADA2 inferred\", length(unqs.mock), \"sample sequences present in the Mock community.\\n\")\n\n# Load expected reference sequences for the Mock community\nmock.ref &lt;- getSequences(file.path(path, \"HMP_MOCK.v35.fasta\"))\nmatch.ref &lt;- sum(sapply(names(unqs.mock), function(x) any(grepl(x, mock.ref))))\ncat(\"Of those,\", sum(match.ref), \"were exact matches to the expected reference sequences.\\n\")\n\n######\n\ntheme_set(theme_bw())\n\nsamples.out &lt;- rownames(seqtab.nochim)\nsubject &lt;- sapply(strsplit(samples.out, \"D\"), `[`, 1)\ngender &lt;- substr(subject,1,1)\nsubject &lt;- substr(subject,2,999)\nday &lt;- as.integer(sapply(strsplit(samples.out, \"D\"), `[`, 2))\nsamdf &lt;- data.frame(Subject=subject, Gender=gender, Day=day)\nsamdf$When &lt;- \"Early\"\nsamdf$When[samdf$Day&gt;100] &lt;- \"Late\"\nrownames(samdf) &lt;- samples.out\n\nps &lt;- phyloseq(otu_table(seqtab.nochim, taxa_are_rows=FALSE), \n               sample_data(samdf), \n               tax_table(taxa))\nps &lt;- prune_samples(sample_names(ps) != \"Mock\", ps) # Remove mock sample\n\ndna &lt;- Biostrings::DNAStringSet(taxa_names(ps))\nnames(dna) &lt;- taxa_names(ps)\nps &lt;- merge_phyloseq(ps, dna)\ntaxa_names(ps) &lt;- paste0(\"ASV\", seq(ntaxa(ps)))\nps\n\n# Alpha diversity\nplot_richness(ps, x=\"Day\", measures=c(\"Shannon\", \"Simpson\"), color=\"When\")\n\n# Beta diversity\nps.prop &lt;- transform_sample_counts(ps, function(otu) otu/sum(otu))\nord.nmds.bray &lt;- ordinate(ps.prop, method=\"NMDS\", distance=\"bray\")\n\nplot_ordination(ps.prop, ord.nmds.bray, color=\"When\", title=\"Bray NMDS\")\n\ntop20 &lt;- names(sort(taxa_sums(ps), decreasing=TRUE))[1:20]\nps.top20 &lt;- transform_sample_counts(ps, function(OTU) OTU/sum(OTU))\nps.top20 &lt;- prune_taxa(top20, ps.top20)\nplot_bar(ps.top20, x=\"Day\", fill=\"Family\") + facet_wrap(~When, scales=\"free_x\")"
  },
  {
    "objectID": "dada.html#understanding-relative-abundance-in-edna-studies",
    "href": "dada.html#understanding-relative-abundance-in-edna-studies",
    "title": "DADA2 Pipeline",
    "section": "Understanding relative abundance in eDNA studies",
    "text": "Understanding relative abundance in eDNA studies\n\n\n\n\n\n\nRRA\n\n\n\nWhen using eDNA, only a portion of the total sample is being used, and then PCR introduces bias by creating millions of DNA copies. This raises the question:\nHow can we trust that the number of DNA reads (or “read counts”) reflects the true abundance of species in the environment?\nPCR amplifies DNA exponentially — ideally doubling the number of DNA copies with each cycle. However, this process introduces amplification bias, such as:\n\nPrimer efficiency bias: some sequences bind primers better and amplify more easily.\nTemplate preference: certain DNA sequences are preferentially copied.\nPlateau effect: as resources deplete, amplification slows and stops.\nSubsampling: only a small portion of the total DNA is used for PCR and sequencing.\n\nThis means PCR doesn’t preserve the original proportions of DNA exactly — it confirms presence, but not perfect abundance. Read counts still be useful but cautiously. While PCR distorts absolute quantities, read counts still carry ecological signals, especially for dominant species. Researchers typically use:\n\nRelative Read Abundance (RRA):\n\n40% of reads = European seabass\n10% of reads = Threespine stickleback\n\n\nRRA allows us to compare patterns across sites or conditions, not exact organism numbers.\nAfter sequencing, a read count table shows how many reads were detected for each species per sample. To make this data comparable, the following techniques are applied:\nNormalisation\nGoal: Adjust for different sequencing depths (i.e. different total read numbers per sample).\n\nProportional scaling: convert raw counts to relative proportions (% of total reads).\nLog transformation: dampens the influence of very abundant species.\nModel-based approaches: e.g. DESeq2, edgeR — account for count variability statistically.\n\nRarefaction\nGoal: Standardise sequencing effort across samples.\n\nSubsample each dataset to a common number of reads (e.g. 10,000 per sample).\nEnsures fair comparisons of diversity.\nPrevents overestimating richness in deeper sequenced samples.\n\nTrade-off: some data (e.g. rare reads) is lost, but results are less biased.\nStatistical tools\nOnce data is normalised or rarefied, we can use various ecological and statistical analyses:\n\nDiversity indices: Shannon, Simpson – to measure species richness and evenness\nOrdination: PCA, NMDS, PCoA – to visualise patterns between sites\nHypothesis testing: PERMANOVA, ANOSIM – to compare groups or treatments\nEcological modelling: Explore links between environmental drivers and communities"
  },
  {
    "objectID": "hu/index.html",
    "href": "hu/index.html",
    "title": "Home",
    "section": "",
    "text": "🧭 Összefoglaló: A teljes munkafolyamat vizuális, lépésről lépésre történő áttekintése\n⚗️ Munkafolyamat: Részletes módszerek, protokollok és anyagok az egyes szakaszokhoz\n🔬 DADA2: Lépésről-lépésre történő útmutató az eDNS-szekvenciaadatok feldolgozásához a DADA2 csővezeték segítségével.\n\n\n\n\n\neDNS fogalom (Forrás: Fishbio)"
  },
  {
    "objectID": "hu/index.html#tartalom",
    "href": "hu/index.html#tartalom",
    "title": "Home",
    "section": "",
    "text": "🧭 Összefoglaló: A teljes munkafolyamat vizuális, lépésről lépésre történő áttekintése\n⚗️ Munkafolyamat: Részletes módszerek, protokollok és anyagok az egyes szakaszokhoz\n🔬 DADA2: Lépésről-lépésre történő útmutató az eDNS-szekvenciaadatok feldolgozásához a DADA2 csővezeték segítségével.\n\n\n\n\n\neDNS fogalom (Forrás: Fishbio)"
  },
  {
    "objectID": "hu/workflow.html",
    "href": "hu/workflow.html",
    "title": "Workflow",
    "section": "",
    "text": "Cél: A vízi életközösség pillanatfelvételének készítése az élőlények által a vízbe kibocsátott DNS összegyűjtésével.\n\n\nGyűjtsetek felszíni vizet palackok vagy vödör segítségével.\n\nA szennyeződés elkerülése érdekében használjon steril mintavételi palackokat és kesztyűt.\n\n*Fakultatív: a környezeti változók (pl. sótartalom, hőmérséklet, DO) rögzítése."
  },
  {
    "objectID": "hu/workflow.html#vízgyűjtés",
    "href": "hu/workflow.html#vízgyűjtés",
    "title": "Workflow",
    "section": "",
    "text": "Cél: A vízi életközösség pillanatfelvételének készítése az élőlények által a vízbe kibocsátott DNS összegyűjtésével.\n\n\nGyűjtsetek felszíni vizet palackok vagy vödör segítségével.\n\nA szennyeződés elkerülése érdekében használjon steril mintavételi palackokat és kesztyűt.\n\n*Fakultatív: a környezeti változók (pl. sótartalom, hőmérséklet, DO) rögzítése."
  },
  {
    "objectID": "hu/workflow.html#szűrés",
    "href": "hu/workflow.html#szűrés",
    "title": "Workflow",
    "section": "🧪 Szűrés",
    "text": "🧪 Szűrés\n\nCél: Koncentráljuk a DNS-nyomokat egy membránra.\n\n\nSzűrje a vizet egy szűrőn (pl. Waterra™) keresztül perisztaltikus szivattyú vagy fecskendő segítségével.\n\nEzek a szűrők a DNS-t és a sejtfragmentumokat a belső membránon fogják fel.\n\nA szűrőket -20 °C-on vagy annál alacsonyabb hőmérsékleten tárolja a DNS integritásának megőrzése érdekében."
  },
  {
    "objectID": "hu/workflow.html#dns-extrakció",
    "href": "hu/workflow.html#dns-extrakció",
    "title": "Workflow",
    "section": "🧬 DNS extrakció",
    "text": "🧬 DNS extrakció\n\nCél: A DNS felszabadítása és tisztítása a szűrőkből, valamint a nem kívánt anyagok eltávolítása.\n\n\nAz eDNS reszuszpendálása\n\nElőzetesen vegye ki a Waterra szűrőket a fagyasztóból, és az extrakció előtt hagyja őket a hűtőszekrényben körülbelül egy órán át felengedni.\nTisztítsa meg a munkaterületet 25%-os fehérítőoldattal és kék tekerccsel.\nTöltsön meg két 50 ml-es Falcon-csövet (Waterra-nként) TE reszuszpenziós pufferrel, ügyelve arra, hogy a csöveket a minta számával jelölje meg.\nRázza ki a maradék vizet a szűrő bemenetéből. Vigyen fel parafóliát, hogy a szűrő sima kivezetőnyílását befedje.\nPipettázzon 50 ml TE reszuszpenziós puffert a kapszulába a bordázott bemeneten keresztül, és zárja le további parafilmmel.\nÖt percig keverjük a kapszulát.\n\nEgy ujjbegyet mindkét végére lehet helyezni, és a kapszulát kézzel rázni, vagy ha a parafilmet biztonságosan a helyére ragasztjuk, a kapszulát örvény ellenében lehet tartani.\n\nÖntse vissza az oldatot az első 50 ml-es Falcon-csőbe, és ismételje meg az 5. és 6. lépést a második 50 ml-es Falcon-csőhöz, így végül két 50 ml-es Falcon-csőbe kerül a szűrőről zavaros TE-pufferben reszuszpendált eDNS.\n\nAz elhasznált Waterra szűrő kidobható.\n\n\n\n\n\n\n\n\nMi az a TE-puffer?\n\n\n\nTE puffer (Tris-EDTA, pH 8,0) a DNS kíméletes kiszabadítására szolgál a Waterra kapszula belsejéből.\n\nTris vagy Tris(hidroxi-metil)aminometán: stabilizálja a pH-értéket.\n\nA stabil, enyhén lúgos pH fenntartása kulcsfontosságú a DNS hidrolízis okozta lebomlásának megakadályozásához, amely felbontja a DNS építőkövei, a nukleotidok közötti kötéseket.\n\n\n\n\nA DNS szerkezete (Forrás: NIH)\n\n\n\nHa a pH csökken (savassá válik), a DNS hajlamosabb a hidrolitikus hasadásra - ez megszakítja a nukleotidok közötti kötéseket, és visszafordíthatatlanul károsíthatja a DNS-t, zavarva az olyan további lépéseket, mint a PCR és a szekvenálás.\n\nEDTA (etiléndiamintetraecetsav): kétértékű kationokat (pl. Mg²⁺, Ca²⁺) köt meg a DNázok gátlása és a DNS integritásának védelme érdekében.\n\n\n\n\n\n\n\n\n\nTE puffer (Tris-EDTA) recept - 5 L összesen\n\n\n\n\n\n🧾 Összetevők (5 literhez)\n\n250 ml 1 M Tris-HCl → Végső koncentráció: → Végső koncentráció: 50 mM (millimoláris)\n100 ml 0,5 M EDTA → Végleges koncentráció: 10 mM (millimoláris)\n4,650 ml ultratiszta víz → A teljes térfogat 5,000 mL (5 L)-ra való növelése érdekében\n\n\n\n\n🧂 Útmutató\n\nEgy tiszta 5 literes üvegpalackban adjuk hozzá: - A folyadékot egy tiszta 5 literes üvegbe, majd a következő anyagokat:\n\n250 ml 1 M Tris-HCl-t.\n100 mL 0,5 M EDTA-t\n\nAdjunk hozzá ultra-tiszta vizet az 5 L-es jelig.\nKeverjük össze alaposan óvatos megfordítással vagy keveréssel.\nCímkézze fel a következővel:\n\nTartalom (pl. “TE puffer, pH 8,0”).\nElkészítés dátuma\nKezdőbetűk\n\nTárolja szobahőmérsékleten.\n\n\n\n\n\n\nCentrifugálás\n\nCentrifugáljuk a két 50 ml-es Falcon-csövet 10 percig 4500 rpm-en (percenkénti fordulatszám, a centrifuga rotor forgási sebességét mérő egység), hogy a törmeléket/üledéket elválasszuk a folyékony DNS-tartalmú frakciótól.\n\nSzupernatáns: az eDNS-t oldatban tartalmazó tiszta felső réteg.\nPellet: a cső alján leülepedett üledék.\n\n\n\n\nSzűrés tölcsérszűrőn keresztül\n\nEgy Buchner-tölcsérhez és perisztaltikus szivattyúhoz csatlakoztatott analitikai tesztszűrő tölcsér segítségével a pufferkeveréket 0,45 mikronos korongszűrőn (Nalgene™) szűrjük át.\nEgyesítsük a két Falcon-csövet mintánként úgy, hogy a most már tiszta felülúszót mindkét csőből átöntjük a tölcséren, és igyekszünk az üledéket a csövekben tartani.\nÁllítsa be a perisztaltikus szivattyú sebességét, hogy a felülúszót áthúzza a tölcséren, és további egy percig szűrje a tölcsér szűrőkorongjának szárításához.\n\nAzok a minták, amelyeknél az üledék felhalmozódása miatt több szűrésre volt szükség, egyetlen analitikai szűrőtölcsérben összevonhatók.\n\nA vizsgálat befejezésekor az egyik tölcsér szűrőkorongjának tartalmaznia kell a szűrt felülúszót, a maradék üledéket pedig az eredeti két Falcon-csőben kell visszatartani.\n\n\n\nQiagen DNeasy PowerWater\n\nSZŰRÉS: Távolítsa el az eldobható szűrőtölcsér felső részét, hogy a szűrőkorong fehér membránja láthatóvá váljon. Használjon steril csipeszt (használjon 25%-os fehérítőoldatot, és öblítse RO-vízzel). Tekerje fel a szűrőmembránt úgy, hogy a felső oldala befelé nézzen, és helyezze be egy 5 ml-es PowerWater DNS-gyöngycsőbe. Adjunk hozzá 1 ml PW1 oldatot.\nSZEDIMENTUM: Adjon 1 mL PW1-oldatot az üledéket tartalmazó Falcon-csövek egyikébe. A PW1-oldattal öblítse ki a csövet a második Falcon-csőbe. Ezt az üledék-PW1 keveréket ezután öntse egy 5 mL PowerWater DNS-gyöngyös csőbe.\n\n\n\n\n\n\n\nPuffer és kit összetevői\n\n\n\n\nPW1 (lízispuffer): Feltöri a sejtfalakat és a membránokat.\n\nLízis: a sejtnek a plazma (külső) membrán károsodása által okozott lebomlása.\n\nProteináz K: Lebontja a fehérjéket és a DNázokat, amelyek egyébként elpusztítanák a DNS-t.\n\nA lipidek és fehérjék PCR-inhibitorokként működhetnek.\n\nGömbök (a gyöngycsőben): A vortexelés során mechanikai bontást biztosítanak, különösen a kemény sejtfalak (pl. baktériumok, algák) esetében.\nQIAshredder oszlop (későbbi lépés): Eltávolítja a sejttörmeléket, így csak a tiszta lizátum jut át rajta.\n\nA lizátum a sejtek felbontásakor keletkező folyadék - olyan keverék, amely az éppen lízingelt (széttört) sejtek teljes belső tartalmát tartalmazza.\nA DNS extrakcióban:\n\nKezdjük a sejtek megbontásával (pl. proteináz K-val és lízispufferrel).\nEzáltal a DNS az oldatba - amelyet most már lizátumnak nevezünk - kerül.\nA cél ennek a lizátumnak a megtisztítása, hogy csak a DNS-t izoláljuk, eltávolítva az összes többi sejtes “szemetet”.\n\n\n\n\n\n\n\n\n\n\n\nTovábbi megjegyzések\n\n\n\n\nMinden extrakciót oldalsó áramlású szekrényben végeztünk, amelyet rendszeresen 25%-os fehérítőszerrel (dH₂O) sterilizáltunk a szennyeződés minimalizálása érdekében.\nA palackokat autoklávoztuk, és minden más eszközt 50%-os fehérítővel sterilizáltunk használat előtt.\nEgy kiegészítő kémiai lízislépést is elvégeztünk 100 µl proteináz K és 900 µl PW1 száraz szűrőpapírt tartalmazó Eppendorf csövekbe történő hozzáadásával.\nA mintákat egy éjszakán át hőblokkban inkubáltuk 56 °C-on, a sejtek alapos lízisének elősegítése érdekében keverés mellett.\nA lízis során a Waterra korongszűrők nagy mennyiségű lizátumot szívtak fel. A DNS kinyerése:\n\nAz átitatott szűrőfragmentumokat QIAshredder oszlopba vittük át.\nA fennmaradó lizátumot a DNeasy protokoll folytatása előtt összekevertük.\n\nMinden extrakciós tételben szerepelt egy negatív kontroll.\nMinden extrakciót és kontrollt kvantitatív módon, Qubit v2 fluorométerrel és az dsDNA BR Assay Kit (Invitrogen) segítségével számszerűsítettünk.\n\n\n\n\n\n\n\n\n\nAnyagok\n\n\n\nA következő anyagok szükségesek a reszuszpenzió, a szűrés és a DNS extrakció lépéseihez:\n\nTE puffer (50 mM Tris, 10 mM EDTA)\n50 ml-es Falcon csövek\nParafilm (a szűrővégek lezárásához)\nBuchner-tölcsér (perisztaltikus szivattyúhoz csatlakoztatva)\n0,45 mikronos korongszűrő (pl. Nalgene™)\nProteináz K (fehérjeemésztéshez)\nQIA-aprító (a lizátum tisztításához)\nDNeasy PowerWater Kit (Qiagen)\nKék tekercs és fehérítőszer (a felületek fertőtlenítéséhez)"
  },
  {
    "objectID": "hu/workflow.html#dns-mennyiségi-meghatározása-qubit",
    "href": "hu/workflow.html#dns-mennyiségi-meghatározása-qubit",
    "title": "Workflow",
    "section": "🔬 DNS mennyiségi meghatározása (Qubit)",
    "text": "🔬 DNS mennyiségi meghatározása (Qubit)\n\nCél: Azt méri, hogy mennyi kettős szálú DNS (dsDNS) van a kivonatban.\n\n\nKészítse el a Qubit munkaoldatot:\n\nKeverje össze a festéket és a puffert 1:200 arányban (pl. 199 µl puffer + 1 µl festék mintánként).\n\nCímkézze fel a vizsgálati csöveket minden standardhoz és mintához.\nAdjunk 190 µl munkaoldatot minden egyes csőbe.\nAdjon 10 µl DNS-mintát (vagy Qubit-standardot) mindegyik csőbe.\nÓvatosan vortexeljen, és inkubálja szobahőmérsékleten 2 percig (fényérzékeny!).\nEgyenként helyezze be a csöveket a Qubitba, és jegyezze fel a koncentrációkat (ng/µL).\n\n\n\n\n\n\n\nVárható eredmények\n\n\n\n\n1-10 ng/µL: Ideális koncentrációtartomány a downstream PCR-hez\n&lt;1 ng/µl: Szükség lehet újraextrakcióra vagy megnövelt PCR-ciklusokra.\nKontrollok:\n\nPozitív kontroll → DNS jelenlétét kell kimutatni.\nNegatív kontroll → 0 ng/µl vagy “Nem kimutatható”.\n\n\n\n\n\n\n\n\n\n\nPuffer és kit összetevői\n\n\n\nKonvertáláshoz:\n\nµL → mL: ossza el 1000-rel (pl. 200 µL ÷ 1 000 = 0,2 mL).\nmL → µL: szorozzuk meg 1000-rel (pl. 1,5 mL × 1 000 = 1 500 µL)."
  },
  {
    "objectID": "hu/workflow.html#pcr-amplifikáció",
    "href": "hu/workflow.html#pcr-amplifikáció",
    "title": "Workflow",
    "section": "📈 PCR-amplifikáció",
    "text": "📈 PCR-amplifikáció\n\nCél: Egy cél-DNS-vonalkód régió felerősítése eDNS-kivonatokból polimeráz láncreakció (PCR) segítségével kimutatható szintre.\n\n\nA PCR egy rövid, szabványosított génrégiót (“vonalkód”) céloz meg, amelyet a fajok azonosítására használnak.\nHalak esetében a 12S rRNS mitokondriális gént szokták vonalkódként használni.\nA primerek rövid, szintetikus DNS-szekvenciák (~18-25 bázispár), amelyek meghatározzák a felerősítendő célrégió kezdő- és végpontját.\nEzek egyedi tervezésűek és kereskedelmi beszállítóktól (pl. IDT, Eurofins) rendelhetők, és elengedhetetlenek a vonalkód régiók szelektív amplifikálásához.\nKét primerre van szükség:\n\nEgy forward primer, amely a vonalkód régió elején lévő egyik szálhoz kötődik (5′→3′ irányban).\nEgy fordított primer, amely a régió végén lévő ellentétes szálhoz kötődik (szintén 5′→3′ írással, de fordított irányban kötődik).\n\nEzek a primerek a vonalkódot szegélyezik, lehetővé téve a DNS-polimeráz számára, hogy a közöttük lévő specifikus régiót lemásolja.\nPélda primerek (MiFish 12S):\n\n(MiFish-U-F): Előre irányuló primer: GTCGGTAAAACTCGTGCCAGC (MiFish-U-F)\nFordított primer: CATAGTGGGGGGTATCTAATCCCCCAGTTTG (MiFish-U-R)\n\nA PCR ismételt hőciklikus ciklizálással történik:\n\nDenaturálás (~94-95 °C): A DNS-szálak egyszálúvá válnak.\nLágyítás (~50-60 °C): Az előre- és a hátrafelé irányuló primerek a cél-vonalkódot kísérő komplementer szekvenciákhoz kötődnek.\nSzintézis/hosszabbítás (72 °C): A DNS-polimeráz (pl. Taq) új DNS-szálakat szintetizál a primerek között.\n\nEz a ciklus ~35-40 alkalommal ismétlődik. Minden egyes ciklus megduplázza a cél-DNS mennyiségét.\n\nAz eredmény csak a vonalkód régió több millió azonos másolata (amplikon) - készen áll a szekvenálásra.\n\n\n\n\nPCR folyamat\n\n\n\n\nA tipikus PCR keverék tartalmazza:\n\neDNS kivonat\nElőre és fordított primerek\nDNS-polimeráz (pl. Taq)\ndNTP-k (A, T, C, G)\nPuffer\n\nKontrollok:\n\nPozitív kontroll: Az amplifikáció megerősítésére ismert DNS-t tartalmaz\nNegatív kontroll: Nincs hozzáadott DNS - a szennyeződés kimutatására\nOptimalizált lágyulási hőmérséklet: Biztosítja a specifikus primer kötődést\n\nA PCR után az amplikonok gélelektroforézissel ellenőrizhetők a szekvenálás előtt.\n\n\n\n\n\n\n\nMi az a Taq polimeráz és mit csinál?\n\n\n\nA Taq-polimeráz egy DNS-polimeráz, amelyet eredetileg a Thermus aquaticus hőtűrő baktériumból izoláltak.\n\nHőstabil, ami azt jelenti, hogy magas hőmérsékleti ciklusokban (pl. 94-95 °C) is aktív marad.\nEz a legszélesebb körben használt enzim a standard PCR-hez, mert:\n\ntűri az ismételt melegítést és hűtést\nHatékonyan szintetizálja a DNS-t ~72 °C-on a hosszabbítási lépés során.\n\n\nA Taq-polimeráz új DNS-szálat épít fel nukleotid-építőblokkok (A, T, C, G) hozzáadásával a sablonszálhoz.\nA primerrel kezdi, és minden bázist a komplementerével párosít:\n\nA párosul T-vel\nC párosul G-vel\n\nEzáltal egy új, komplementer szál jön létre - lényegében lemásolva az eredeti DNS-t."
  },
  {
    "objectID": "hu/workflow.html#gélelektroforézis",
    "href": "hu/workflow.html#gélelektroforézis",
    "title": "Workflow",
    "section": "🧫 Gélelektroforézis",
    "text": "🧫 Gélelektroforézis\n\nCél: A sikeres PCR-amplifikáció vizuális megerősítése és a szennyeződések kiszűrése.\n\n\nA PCR-termékeket agaróz gélbe töltik, amely egy tengeri moszatból származó poliszacharidból készült porózus mátrix.\n\n\n\n\n\nDNS elektroforézis berendezés\n\n\n\n\nAmikor elektromos áramot alkalmazunk:\n\nA negatív töltésű DNS a pozitív elektróda felé vándorol.\nA kisebb fragmentumok gyorsabban mozognak a gél pórusain keresztül.\nA nagyobb fragmentumok lassabban mozognak.\n\nA gél lefuttatása után a DNS-t fluoreszcens festékkel (pl. GelRed vagy SYBR Safe) festjük meg és UV vagy kék fényben láthatóvá tesszük.\nHasonlítsa össze az egyes minták sávjait egy DNS létrával (méretjelző):\n\n*Elvárt méretű tiszta sáv** (pl. 200-600 bp a 12S esetében): A PCR valószínűleg sikeres volt.\n\nbp (bázispár): a DNS-darabkák hosszának mérésére használt egység.\n1 bp = 1 bázispár (A-T vagy C-G)\n200-600 bp azt jelenti, hogy a DNS-fragmentum 200-600 bázispár hosszú.\n\nKeveredés vagy többszörös sávok: Nem specifikus amplifikáció vagy lebomlott DNS\n*Nincs sáv**: A PCR sikertelen volt vagy a DNS-templát nem volt elegendő\n\nA kontrollsávoknak mutatniuk kell:\n\nPozitív kontroll → Sáv jelen van a várt méretben\nNegatív kontroll → Nincsenek sávok (megerősíti a szennyeződés hiányát)\nMinták → A célgéntől függő, konzisztens méretű sávok\n\n\nSetup példa\n\n\n\nSáv\nTartalom\n\n\n\n\n1\nHyperladder (méretjelző)\n\n\n2\nPozitív kontroll DNS\n\n\n3\n1. minta\n\n\n4\n2. minta\n\n\n…\n…\n\n\nN\nNegatív extrakciós kontroll\n\n\n\n\n\n\n\nGélen elválasztott DNS-sávokat ábrázoló ábra\n\n\n\n\n\n\n\n\n\nAnyagok\n\n\n\n\nAgaróz gél\nTAE vagy TBE puffer\n\npH fenntartása (~8,0)\nVezessünk elektromos áramot\nEDTA-t tartalmaz a DNázok gátlására\n\nDNS festék (GelRed vagy SYBR Safe)\nHyperhárító (DNS méretjelölő)\nGélöntő tálca és fésű\nElektroforéziskamra és tápegység\nUV vagy kék fényű transzilluminátor"
  },
  {
    "objectID": "hu/workflow.html#szekvenálás",
    "href": "hu/workflow.html#szekvenálás",
    "title": "Workflow",
    "section": "📦 Szekvenálás",
    "text": "📦 Szekvenálás\n\nCél: A (PCR során előállított) felerősített vonalkód régiók DNS-szekvenciáinak leolvasásával meghatározni, hogy mely fajok vannak jelen a mintában.\n\nLépések:\n\nPooling\n\nA különböző mintákból származó PCR-termékeket (amplikonokat) egyetlen szekvenáló könyvtárrá - a szekvenáláshoz előkészített DNS-fragmentumok kollektív pooljává - egyesítik.\n\nBárkódolás (indexelés)\n\nMinden mintát egy egyedi rövid DNS-szekvenciával (vonalkód/index) jelölünk.\n→ Ez lehetővé teszi annak azonosítását, hogy a szekvenálás után melyik szekvencia melyik mintából származik.\n→ A folyamatot multiplexálásnak nevezik.\n\nSzekvenálás\n\nA végleges könyvtárat betölti egy nagy áteresztőképességű szekvenáló platformba, jellemzően egy Illumina MiSeq-be.\nAz Illumina az úgynevezett szintetikus szekvenálás módszert alkalmazza:\n\nA DNS-darabkákat egyszerre egy bázist másolnak le.\nMinden egyes bázis hozzáadásakor fluoreszcens jelet bocsát ki:\n\nA = zöld\nT = piros\nC = kék\nG = sárga\n\nA kamera ezeket a jeleket bázisonként színes villanások sorozataként rögzíti.\n\nMinden egyes szekvenálási futtatás FASTQ-fájlokat készít, amelyek a következőket tartalmazzák:\n\nMillió rövid DNS-olvasat (jellemzően 150-300 bázispár).\nminőségi pontszámok minden egyes bázisra vonatkozóan\nMinden leolvasás ideális esetben az amplifikált vonalkód régió** (pl. halak esetében a mitokondriális 12S rRNS) egy **másolatának felel meg.\n\nPélda: Az “AGCCTTGAGAACTGCTTAC…` típusú olvasatot egy referenciaadatbázissal való összehasonlítással európai tengeri sügérként lehet azonosítani."
  },
  {
    "objectID": "hu/workflow.html#bioinformatika",
    "href": "hu/workflow.html#bioinformatika",
    "title": "Workflow",
    "section": "💻 Bioinformatika",
    "text": "💻 Bioinformatika\n\nCél: A nyers DNS-szekvencia-adatok feldolgozása és értelmezése annak érdekében, hogy azonosítani lehessen, mely fajok voltak jelen az egyes mintákban.\n\n\nA szekvenálás után (pl. Illumina MiSeq) minden egyes minta FASTQ-fájlokat - szöveges fájlokat - eredményez, amelyek a következőket tartalmazzák:\n\nTöbb millió rövid DNS-olvasat\nMinden bázisra vonatkozó minőségi pontszám, amely jelzi a bázishívások megbízhatóságát.\n\nMinőségi szűrés:\n\nA alacsony minőségű olvasatok és a megbízhatatlan bázishívások eltávolítása.\nLevágás:\n\nMaradék primerek\nAdapter szekvenciák\nZajos bázisok a végeken\nGyakori eszközök: cutadapt,fastp,Trimmomatic`.\n\n\nZajmentesítés és dereplikáció:\n\nItt központi szerepet játszik a [DADA2] (https://benjjneb.github.io/dada2/index.html).\n\n\n\n\n\n\n\n\nMi az a DADA2?\n\n\n\nA DADA2 (Divisive Amplicon Denoising Algorithm 2) egy R csomag, amely a nyers leolvasásokat pontos szekvenciákká alakítja, amelyeket Amplicon Sequence Variants (ASVs)-nak nevezünk.\nModellezi és korrigálja a szekvenálási hibákat, hogy visszanyerje a mintákban található igaz biológiai szekvenciákat.\n\n\n\n\n\n\n\nLépés\nMit csinál a DADA2\n\n\n\n\nHibaarányok megtanulása\nFelépíti a szekvenálási hibaminták modelljét\n\n\nHibajavítás\nKorrigálja a hibákat és feloldja a valódi szekvenciákat\n\n\nDereplikálás\nAz azonos olvasatokat egyedi szekvenciákká egyesíti + számol\n\n\nMerge reads\nPárosított végű olvasatok kombinálása (forward + reverse)\n\n\nKimérák eltávolítása\nEltávolítja a PCR mesterséges rekombinációs termékeit\n\n\nTaxonómia hozzárendelése\nAz ASV-ket egy referencia adatbázis (pl. MiFish, GenBank) segítségével címkézi\n\n\n\n\n\n\nTaxonómiai hozzárendelés:\n\nAz ASV-ket egy referencia adatbázis segítségével párosítják ismert fajokkal vagy nemzetségekkel.\nKözös adatbázisok:\n\nGenBank - Széleskörű nukleotid adatbázis.\nMiFish - Hal-specifikus 12S rRNS-strichkódok.\nBOLD - Barcode of Life Data System (különösen a COI génre vonatkozóan)\n\nTársítási eszközök:\n\nBLAST - Megkeresi a legközelebbi egyezést egy adatbázisban (pl. ASV AGCCTTGAGAACTGCTTAC... → Dicentrarchus labrax (európai tengeri sügér), 99,3%-os azonosság).\nQIIME2 - Végponttól-végpontig tartó csővezeték taxonómiai bővítményekkel (pl. BLAST, naiv Bayes).\nMEGAN - BLAST eredmények átalakítása taxonómiai fákká és összefoglalókká.\n\n\nItt az anonim DNS-fragmentumok fajneveket kapnak - az adatokat ökológiai jelentéssé alakítja át.\n\n\n\n\n\n\n\nTaxonómiai hozzárendelés BLAST és BASTA segítségével\n\n\n\nBLAST a Basic Local Alignment Search Tool rövidítése.\n\nAz ismeretlen DNS-szekvenciát (pl. egy ASV-t) hasonlítja össze egy referenciaadatbázissal, például a GenBankkal, a BOLD-dal vagy a MiFish-sel, hogy megtalálja a leghasonlóbb ismert szekvenciákat.\nJelentést készít:\n\n% azonosság - Mennyire hasonlít az Ön szekvenciája a referenciához.\nQuery Coverage - Az ASV-je mekkora része illeszkedik a referenciához.\nérték - Az egyezés valószínűsége véletlenszerű (az alacsonyabb érték a jobb)\n\nPélda:\n\n… Legjobb egyezés: Dicentrarchus labrax (európai tengeri sügér)\nEredmény: 99,3%-os azonosság, 98%-os lefedettség, E-érték = 2e-50\nErős bizonyíték arra, hogy ez az ASV az európai tengeri sügérből származik.\n\n\nA BASTA a BLAST-alapú rendszertani hozzárendelés rövidítése.\n\nA BASTA egy olyan eszköz, amely a BLAST-eredményekre építve automatizált és reprodukálható rendszertani hozzárendelést biztosít az utolsó közös ős (Last Common Ancestor, LCA) megközelítéssel.\nMíg a BLAST a lehetséges találatok listáját adja meg, a BASTA összefoglalja ezeket a találatokat, és a taxonómiai hozzárendelést a következők alapján végzi:\n\nA legjobb találatok konszenzusa\na felhasználó által meghatározott azonossági és lefedettségi küszöbértékek\nA legjobb találatok által osztott legalacsonyabb közös rendszertani rangsor (LCA).\nEz segít elkerülni a túlságosan specifikus vagy helytelen fajmeghatározásokat.\n\n\nA BLAST megtalálja az adatbázisban a legjobban illeszkedő szekvenciákat, a BASTA pedig a BLAST-találatok konszenzusának felhasználásával rendeli hozzá a rendszertani rendszert.\n\n\n\nBőségtáblázat generálása:\n\nA végső lépés egy fajonkénti mátrix létrehozása a biológiai sokféleség mintáinak vizualizálása érdekében.\n\n\n\n\n\nFajok\n1. minta\n2. minta\n3. minta\n\n\n\n\nEurópai tengeri sügér\n2134\n98\n712\n\n\nHáromtüskés pálcikacsáp\n435\n0\n220\n\n\nGoby spp.\n12\n33\n8\n\n\n\n\nEz az eljárás több millió névtelen DNS-darabkát alakít át használható felismerésekké:\n\nMilyen fajok voltak jelen?\nMelyik helyszínen volt nagyobb a biológiai sokféleség?\nHogyan változtak a közösségek térben vagy időben?"
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "Summary",
    "section": "",
    "text": "💧 Water collection\n→ Collect environmental water samples using sterile techniques.\n🧪 Filtration\n→ Pass water through membrane filters to capture suspended DNA (eDNA) from the environment.\n🧬 DNA extraction\n→ Isolate DNA from the filters using a commercial extraction kit (e.g. Qiagen DNeasy).\n🔬 DNA quantification (Qubit)\n→ Measure DNA concentration to assess extraction success and ensure enough material for PCR.\n📈 PCR Amplification\n→ Use primers to target and amplify a barcode gene (e.g. mitochondrial 12S rRNA) via thermal cycling.\n🧫 Gel electrophoresis\n→ Run PCR products on an agarose gel to check for successful amplification and absence of contamination.\n📦 Sequencing\n→ Pool PCR amplicons, add sample-specific barcodes (indexes), and sequence using a platform like Illumina MiSeq.\n💻 Bioinformatics\n→ Demultiplex, quality-filter, and assign taxonomy to sequence data using a bioinformatics pipeline (e.g. DADA2)."
  }
]